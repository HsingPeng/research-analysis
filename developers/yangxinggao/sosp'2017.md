## Section 2: Scalability

### Scaling a file system to many cores using an operation log（精读）
延续了A. Clements 在fs scalability方面的工作，这里的fs增加了同步到非易失介质上的功能。在提高scalability的同时，考虑crash safety的问题。

系统保存一个操作的记录，每个核心都有各自的log，当需要向磁盘写入的时候，系统按照时间戳合并这些log，去除可以低效的操作对，最后一并向磁盘写入。

这样文件系统便分成了两个独立的部分：一个in-memory，用来提高scalability；另一个on-disk，用来提高写入的吞吐量；这一点很类似JFS。

论文主要就在描述crash-safe和吞吐量的取舍，如何正确的记录与合并log，并且用commuter的方法增加scalability（不过由于上层API没什么变化，我怀疑这里应该没有做什么事情）。

## Section 5: Kernels

### Multiprogramming a 64 kB Computer Safely and Efficiently (精读）
之前在嵌入式系统中只运行一个程序，系统本身和程序是混在一起的，而现在，一个嵌入式程序变成了一个软件平台，有多个类似与进程的组件交替运行。论文就是想在资源不足且需要满足嵌入式系统的特殊需求的情况下，提供一个多道程序系统，进行内存管理，容错和调度。

实现主要分为系统功能和驱动的capsule部分，和用户程序的进程部分。

系统由Rust实现的capsule组成，借助Rust的特性，capsule具有可靠，内存高效，并发，内存错误隔离等特性。capsule有许多种类，来满足不同组件的特性和需求。同时，除了一些底层的capsule之外，其他的capsule并不是可信的，由Rust来保证capsule间和capsule与进程间的隔离。  
内核由事件驱动，capsule不会产生新的事件来避免overhead。

进程同capsule不同，可以使用任何语言实现。系统提供与一般系统相似的进程，保证进程间内存隔离。但是不同的是，没有无限大的虚拟内存，调用的内核API是非阻塞的。同时，是可抢占的。

由于可用的内存如此之少，系统采用一个叫grant的方式管理内存：当内核加载一个进程时，内核基于设置和需求，分配一段内存块，进程自下而上将自己的数据放入其中，剩下的部分是系统所用的grant。当进程和capsule交互的时候，capsule会使用这部分grant内存，而进程本身不可访问grant区域。

实现之后，Tock内核本身占8.4kB的SRAM，额外4kB作为内核栈，以及87kB的flash，其余的均为进程保留。

> 没有太仔细看evaluation，但是作为一个嵌入式系统，可靠性和实时性实际上非常重要，这一部分有空的时候看一看。  
> 同时作为一个系统，有很多的细节，光知道大概是这样实现的其实并没有弄清楚这个工作的意义，应该还是要重新读一下。

## Section 6: Verification

### Hyperkernel: Push-Button Verification of an OS Kernel (精读)
作者希望将之前用在文件系统上的证明方法重用在OS内核上。针对系统的复杂性，做了以下几件事：
- 简化接口实现，加入对于接口的额外规定：finitized
- 使用llvm中间表达（IR）进行证明，而非C语言
- 简化系统内存管理实现

同时还额外要求系统是单处理器关中断的，对于其他的也有额外的要求。

论文给出了他认为较好的specification表述：一个状态机用于描述调用如何工作，一个更为高级的自然语义表述便于人理解。

证明过程依然类似之前的工作，用python描述specification，用Z3求解，给出证明或者testcase。

> 这个工作是不是作偏了？从希望系统证明变为不断修改系统本身来满足求解器和证明过程的不足。  
> 就我对CSAIL这一系列程序证明的工作来看，最直接的方法还是给出一个well-defined and appropriate specification.

### Verifying a high-performance crash-safe file system using a tree specification （精读）
这个工作就延续了Frans之前的思路：抽象出一个实际的文件系统的specification。这个specification应该是严格完备的，不应有太多的具体实现细节，同时又要便于实现。

和以往的文件系统证明不同的地方：
- 给出了fdatasync和fsync的specification的比较严格的形式
- 这个specification可以抽象出比较复杂的性能优化方法（log-bypass write）

论文的specification采用metadata的树定义，每个操作都会产生新的树，crash被允许在上一次fsync之后任意操作处发生。作者希望这样能够严格的定义出具体的操作，同时省略具体细节，便于开发者理解文件系统的状态。

## Section 8: Adaption and Repair

### Automatically Repairing Network Control Planes Using an Abstract Representation（泛读）
由于网络控制层（control plane）的设置非常复杂：不同路由之间有很多不同的协议，且路由之间不是互相孤立的，修改一个路由设置可能会引入新的问题。论文希望能提供了一种证明和修复的方法：抽象出整个控制层的带层次结构有向图，确定相邻路由和同一个路径上路由间协议和设置的相关性，按照确定算法遍历得到约束。同时为了使得修改的部分最小，额外添加约束。最后转化成一个MAX-SMT问题（NP-Hard），用z3求解。

> 比较新颖的内容应该是HARC，简而言之，是网络控制层的specification的有向图表示，对于抽象出一个specification有一定的借鉴意义。  
> 另外，求解SMT依然是相似的，但是和FS不同的是，每一个policy都有不同的要求，需要依此添加约束，这里的思路也是蛮值得借鉴的。  
> specification的抽象尽量小的同时，应该还是要同时兼顾到完备性。Hyperkernel的状态机和这里的有向图实际上是相似的，都是为了尽量的完备地描述状态（路径）变化。

### Drizzle: Fast and Adaptable Stream Processing at Scale（泛读）
大规模流处理系统（Large scale streaming processing system），例如spark，hadoop，需要同时满足高吞吐量，低延迟，对于错误和工作量变化的快速反应等等需求。
此前的工作在这三者上往往有所取舍。作者基于**流任务需要毫秒级的处理延迟，而工作量和集群的变化率是分钟级的，远低于任务延迟需求**这一发现，降低了容错和自适应需要的同步率（？翻译的很乱但是意思我是明白的）。最后在spark上实现了更低的延迟，更快的故障恢复速度。
> 类似DCTCP，这个工作分析workload和cluster的特性，设计算法对于变化进行反馈，进而消除不必要的overhead。其中关于dataplane和batch的使用其实可以多了解一下。
> 算是scalability类型的问题。
