# 周报告——何钦尧

## 2017.4.17 ~ 2017.4.24

### 本周工作计划点1

使用Docker的容器限制实验环境的计算资源。

已经做到可以限制Docker中的CPU核心数量，内存总量，以及磁盘IO的带宽和速率的限制。Docker暂时没有控制网络IO的功能。

详细参见[Docker容器资源限制](https://github.com/openthos/research-analysis/blob/master/developers/何钦尧/Docker容器资源限制.md)

### 本周工作计划点2

尝试实现最简单的在线异常检测算法。

尝试使用moving average来对数据流进行统计，计算出其均值和标准差。使用高斯分布的$3\sigma$进行检验，任何一个维度的坐标超出$3\sigma$之外的视作为异常点。

能够达到实时检测的性能。在实际应用当中，经过比较长的时间的数据积累之后，对于分布的均值和方差的估计都变得比较恰当，能比较好的检测出突发的异常。然而异常数据点在进入到数据中之后，会对原有的数据分布产生很大的影响，导致之后的检测性能变差，需要比较长时间才能恢复回来。

### 下周计划

* 参考论文，实现更有效的在线异常检测算法（比如使用Local Outlier Factor）
* 对于异常点进行各种统计量偏差的计算（相对于正常类的聚类中心）
* 重构实验程序，使其模块化结构化

## 2017.4.10 ~ 2017.4.16

### 本周工作计划点1

读了一篇对于系统性能异常检测的综述性的文章《Performance Anomaly Detection and Bottleneck Identification》，研究了其中涉及到的各种相关文献，[Note](https://github.com/openthos/research-analysis/blob/master/developers/何钦尧/Performance-Anomaly-Detection-and-Bottleneck-Identification-Notes.md)。所有相关文章的实验思路都是通过注入（inject）某种异常进入系统然后使用算法进行检测，计算其正确率等性能指标。

### 下周计划

由于实验的机器的性能比较强，实际实验中限制机器的性能会能够比较有效的制造出性能的异常，因此使用docker限制实验环境的资源进行试验。

试图去实现上面的一篇文章里面的在线异常检测的算法。

## 2017.3.27 ~ 2017.4.9

### 工作计划点1

准备中期答辩。

中期答辩之前的工作主要都是在自己模拟的环境下进行的，要验证算法的有效性还需要更多的真实场景的数据。

未来的工作需要解决几个问题：

1. 在线学习，模型能够自适应系统运行状态的变化，并在系统中实时的高效的运行。
2. 序列学习，模型要能够挖掘出序列特征，而不仅是点的特征。
3. 真实场景的数据的构建。

### 下周计划

寻找相关类似工作的文献，找寻有没有已有的工作有做数据集一类的东西。

尝试进行时间序列特征的学习和异常检测。

## 2017.3.13 ~ 2017.3.26

上个周忘了写周报，本周补写两周的工作。

### 本周工作计划点1

构造一个程序的运行影响另一个程序的性能的样例（通过卡磁盘IO的方法），从统计数据中进行异常性的检测。

工作程序是对输入文件计算md5的hash值。这是一个相对来说IO密集的程序（经测试跑满单核CPU占用率需要的磁盘读取速率为300MB/s）。

攻击程序是一个不断的随机读取大量小文件的程序。测试中每个小文件的大小也就几十个字符。通过随机读取这些小文件产生大量磁盘寻道时间的开销，降低磁盘的性能（主要占用的不是带宽，这些读取并不能达到非常高的带宽）。

在实际的测试中我发现，由于Linux系统会在内存中对打开过的文件的内容进行缓存，下一次读取的时候就不再从磁盘中读取。这给实验的重复性造成了很多的困难。为了解决这个问题花了不少的功夫。最后采用的办法是，将需要读取的文件做的非常大（超过内存的大小，我产生了大概40G左右的大文件和小文件），以及通过以下一条命令

```bash
echo 3 > /proc/sys/vm/drop_caches
```

来告诉Linux内核将内存中的Cache给清理掉，在每次做完实验之后，都运行该命令，给之后的实验制造一个车干净的环境。

在运行工作程序的时间中（大约100秒），间歇性的运行攻击程序（每次运行三四秒的时间）。然后通过另一个进程收集相关统计数据。之后使用非监督学习的方法来检测这些产生异常的时间段。对于三段异常都做到了比较好的检测。

详见：https://github.com/hqythu/graduate-project/blob/master/iotest/iotest.ipynb

### 实验相关讨论

当前依然只能做到离线的检测，合理的在线的检测方法现在还没有什么思路。

没有充分利用序列信息。

从/proc中获取的进程统计数据种类十分有限，比如没有对于每个进程的iowait数据。需要挖掘更多的数据源。

未来进一步的工作可能需要补一补在线学习和时间序列分析的相关理论。

### 下周计划

主要是准备中期答辩。然后试图直接改为在线的使用离线检测方法利用所有的数据（当前的模型计算量还不是很大，可以接受）。

去找寻更多的统计数据的来源。

## 2017.3.5 ~ 2017.3.12

### 本周工作计划点1

完成Anomaly Detection: A Survey的阅读。后半部分集中在Contextual Anomalies。对于context中的anomaly detection，文中只提到了一种reduction to point anomaly的方法，其他的只是提到了相关的文献。这种reduction的方法需要鉴别出一个contextual和behaviorial的特征，我认为不太可能适合现在的任务。

文中列出的关于Sequence Anomaly Detection的若干工作有以下一些参考文献：

[https://link.springer.com/article/10.1007/s10115-006-0026-6](https://link.springer.com/article/10.1007/s10115-006-0026-6)

[http://wenke.gtisc.gatech.edu/ids-readings/system_call_models.pdf](http://wenke.gtisc.gatech.edu/ids-readings/system_call_models.pdf)

[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.69.3285&rep=rep1&type=pdf](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.69.3285&rep=rep1&type=pdf)

暂时还没有来得及阅读。

### 本周工作计划点2

尝试使用无监督学习的方式从带有少量异常数据点的数据中检测出异常点。

直接使用了上一次的实验数据。使用了两种非监督的异常检测方法, elliptic envelope, isolation forest。原来的one class svm并不适合现在的带有负样本的数据的情况（会导致负样本依然被划进决策曲面内）。

在我的目前的实验情况中，elliptic envelope的效果比较差，而isolation forest的比较好，但总体都比之前的监督学习的效果要差（预料之中的）。但是这里的问题是我没有对feature进行normalization之类的预处理，也没有仔细的调节模型的参数，可能没有达到模型最好的性能。

考虑到算法的性能存在一定的问题，而且我们面临的是时间序列的模型，可能需要自行开发设计适合这个问题的检测算法了。

整理了本周和上一周的结果放在了一个Jupyter Notebook中，https://github.com/hqythu/graduate-project/blob/master/anomaly_detection_prototype.ipynb

### 下周计划

根据和陈渝老师讨论的结果，尝试构造一个程序的运行影响另一个程序的性能的样例（初步考虑是通过卡IO的方式），并尝试对其中进行一些检测。

找寻更多的关于sequence anomaly detection的相关文章并阅读。

## 2017.2.25 ~ 2017.3.5

### 本周工作计划点1

阅读综述文章：[Anomaly Detection: A Survey](http://cucis.ece.northwestern.edu/projects/DMS/publications/AnomalyDetection.pdf)的前半部分内容。对于文中提到的6个分类的异常检测方法，除了Information Theory相关的，基本上属于我比较熟悉的机器学习方法。文章的后半部分主要涉及到处理Contextual Anomalies，比如空间信息和时间序列信息中的相关处理。这想象中应该是比较需要的。考虑到多数情况下是随时间演化统计的各种信息，考察时间序列上的变化是很必要的。

此外，当前发现的算法应该都是基于离线学习的。即有一定数量的训练数据集之后，训练一个模型出来用来识别。没有发现有在线学习方法（即实时的通过一直都在产生的数据来调整模型）。在线学习想象中也是有必要的，通过实时收集数据并自发的调整模型应该是一个很重要的目标。这方面还需要进一步挖掘。在线学习我懂的不太多，可能可以尝试用我知道的一点在线学习方法往上面套一下试试看。

### 本周工作计划点2

构造特定程序，其修改可以引起已知的某种性能变化。尝试用算法检测。

构造了两个程序，其中之一是使用两种不同的排序算法对随机生成的数进行排序，收集程序的运行时间作为数据。以其中一个算法的运行数据构造One Class SVM Classifier，然后用来预测另一个算法的数据。期望中应该能够区分出另一个算法。在非常噪声（方差比较大）的数据中，对于另一类的预测准确率达到80%。

程序二是使用Python编写了一个http server和一个client，server通过随机sleep来模拟产生随机的网络延迟，client循环对server进行http访问。网络延迟的不同会导致client在性能统计指标上的不同。我使用了在/proc文件系统对于client进程选择的4个数据（utime，stime，voluntary_ctxt_switches, nonvoluntary_ctxt_switches），以1秒为时间间隔收集数据。同样在服务端使用不同的分布产生随机延迟，并利用其中的一组作为训练来尝试检测另一组，达到非常高的准确率。

### 下周计划

- 完成Anomaly Detection: A Survey的阅读。
- 尝试使用无监督学习的方式从带有少量异常数据点的数据中检测出异常点。

> > 很好，基于我们的讨论，希望本周有新的进展。

## 2017.02.18~2017.02.24

### 本周工作计划点1

研究论文《Detecting Large-Scale System Problems by Mining Console Logs》和引用它的若干文献，尝试了解背景方法。

### 完成情况

这若干篇文章的重点似乎都比较集中在如何对Log信息进行解析，而不在使用何种数据分析的方法。

#### 论文阅读进展

异常检测方法的一篇很好的综述 [Anomaly Detection: A Survey](http://cucis.ece.northwestern.edu/projects/DMS/publications/AnomalyDetection.pdf)

### 下周计划

- 读完一半左右的Anomaly Detection: A Survey
- 人工构造一个特定的应用程序，可以通过修改引起某个已知的指标的变化，尝试使用算法从统计信息中检测出这种变化